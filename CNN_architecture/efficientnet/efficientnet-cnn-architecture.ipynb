{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install efficientnet_pytorch","metadata":{"execution":{"iopub.status.busy":"2023-07-22T21:22:42.570063Z","iopub.execute_input":"2023-07-22T21:22:42.570983Z","iopub.status.idle":"2023-07-22T21:22:54.996333Z","shell.execute_reply.started":"2023-07-22T21:22:42.570938Z","shell.execute_reply":"2023-07-22T21:22:54.995177Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: efficientnet_pytorch in /opt/conda/lib/python3.10/site-packages (0.7.1)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from efficientnet_pytorch) (2.0.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet_pytorch) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet_pytorch) (4.6.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet_pytorch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet_pytorch) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet_pytorch) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->efficientnet_pytorch) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->efficientnet_pytorch) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms, datasets\nfrom efficientnet_pytorch import EfficientNet\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\nimport torch.nn.functional as F\n","metadata":{"execution":{"iopub.status.busy":"2023-07-22T21:22:55.003364Z","iopub.execute_input":"2023-07-22T21:22:55.003808Z","iopub.status.idle":"2023-07-22T21:22:57.283046Z","shell.execute_reply.started":"2023-07-22T21:22:55.003762Z","shell.execute_reply":"2023-07-22T21:22:57.281914Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"# Set random seed for reproducibility\ntorch.manual_seed(42)\n\n# Define transformations to resize and normalize images\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),  # Resize to match EfficientNetB0's input size\n    transforms.Grayscale(num_output_channels=3),  # Convert to 3 channels (RGB)\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.5], std=[0.5])  # Normalize to range [-1, 1]\n])\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-07-22T21:22:57.284631Z","iopub.execute_input":"2023-07-22T21:22:57.285662Z","iopub.status.idle":"2023-07-22T21:22:57.293954Z","shell.execute_reply.started":"2023-07-22T21:22:57.285623Z","shell.execute_reply":"2023-07-22T21:22:57.292915Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Load MNIST dataset using torchvision.datasets\ntrain_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\ntest_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n","metadata":{"execution":{"iopub.status.busy":"2023-07-22T21:22:57.297235Z","iopub.execute_input":"2023-07-22T21:22:57.298011Z","iopub.status.idle":"2023-07-22T21:22:57.395672Z","shell.execute_reply.started":"2023-07-22T21:22:57.297971Z","shell.execute_reply":"2023-07-22T21:22:57.394526Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Create data loaders for training and testing\nbatch_size = 64\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-07-22T21:22:57.397570Z","iopub.execute_input":"2023-07-22T21:22:57.397999Z","iopub.status.idle":"2023-07-22T21:22:57.405016Z","shell.execute_reply.started":"2023-07-22T21:22:57.397950Z","shell.execute_reply":"2023-07-22T21:22:57.403753Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class EfficientNetMNIST(nn.Module):\n    def __init__(self, num_classes=10):\n        super(EfficientNetMNIST, self).__init__()\n        self.base_model = EfficientNet.from_pretrained('efficientnet-b0')  # Load pre-trained weights\n        self.base_model._fc = nn.Linear(in_features=1280, out_features=num_classes, bias=True)\n\n    def forward(self, x):\n        return self.base_model(x)","metadata":{"execution":{"iopub.status.busy":"2023-07-22T21:22:57.406577Z","iopub.execute_input":"2023-07-22T21:22:57.407918Z","iopub.status.idle":"2023-07-22T21:22:57.419252Z","shell.execute_reply.started":"2023-07-22T21:22:57.407882Z","shell.execute_reply":"2023-07-22T21:22:57.418046Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Initialize the model\nmodel = EfficientNetMNIST()\n\n# Define the loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# Training loop\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2023-07-22T21:22:57.420729Z","iopub.execute_input":"2023-07-22T21:22:57.421178Z","iopub.status.idle":"2023-07-22T21:22:59.369120Z","shell.execute_reply.started":"2023-07-22T21:22:57.421143Z","shell.execute_reply":"2023-07-22T21:22:59.367846Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Loaded pretrained weights for efficientnet-b0\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"EfficientNetMNIST(\n  (base_model): EfficientNet(\n    (_conv_stem): Conv2dStaticSamePadding(\n      3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False\n      (static_padding): ZeroPad2d((0, 1, 0, 1))\n    )\n    (_bn0): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n    (_blocks): ModuleList(\n      (0): MBConvBlock(\n        (_depthwise_conv): Conv2dStaticSamePadding(\n          32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False\n          (static_padding): ZeroPad2d((1, 1, 1, 1))\n        )\n        (_bn1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_se_reduce): Conv2dStaticSamePadding(\n          32, 8, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_se_expand): Conv2dStaticSamePadding(\n          8, 32, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_project_conv): Conv2dStaticSamePadding(\n          32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn2): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_swish): MemoryEfficientSwish()\n      )\n      (1): MBConvBlock(\n        (_expand_conv): Conv2dStaticSamePadding(\n          16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn0): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_depthwise_conv): Conv2dStaticSamePadding(\n          96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False\n          (static_padding): ZeroPad2d((0, 1, 0, 1))\n        )\n        (_bn1): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_se_reduce): Conv2dStaticSamePadding(\n          96, 4, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_se_expand): Conv2dStaticSamePadding(\n          4, 96, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_project_conv): Conv2dStaticSamePadding(\n          96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_swish): MemoryEfficientSwish()\n      )\n      (2): MBConvBlock(\n        (_expand_conv): Conv2dStaticSamePadding(\n          24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_depthwise_conv): Conv2dStaticSamePadding(\n          144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False\n          (static_padding): ZeroPad2d((1, 1, 1, 1))\n        )\n        (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_se_reduce): Conv2dStaticSamePadding(\n          144, 6, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_se_expand): Conv2dStaticSamePadding(\n          6, 144, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_project_conv): Conv2dStaticSamePadding(\n          144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_swish): MemoryEfficientSwish()\n      )\n      (3): MBConvBlock(\n        (_expand_conv): Conv2dStaticSamePadding(\n          24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_depthwise_conv): Conv2dStaticSamePadding(\n          144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False\n          (static_padding): ZeroPad2d((1, 2, 1, 2))\n        )\n        (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_se_reduce): Conv2dStaticSamePadding(\n          144, 6, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_se_expand): Conv2dStaticSamePadding(\n          6, 144, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_project_conv): Conv2dStaticSamePadding(\n          144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_swish): MemoryEfficientSwish()\n      )\n      (4): MBConvBlock(\n        (_expand_conv): Conv2dStaticSamePadding(\n          40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_depthwise_conv): Conv2dStaticSamePadding(\n          240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False\n          (static_padding): ZeroPad2d((2, 2, 2, 2))\n        )\n        (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_se_reduce): Conv2dStaticSamePadding(\n          240, 10, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_se_expand): Conv2dStaticSamePadding(\n          10, 240, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_project_conv): Conv2dStaticSamePadding(\n          240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_swish): MemoryEfficientSwish()\n      )\n      (5): MBConvBlock(\n        (_expand_conv): Conv2dStaticSamePadding(\n          40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_depthwise_conv): Conv2dStaticSamePadding(\n          240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False\n          (static_padding): ZeroPad2d((0, 1, 0, 1))\n        )\n        (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_se_reduce): Conv2dStaticSamePadding(\n          240, 10, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_se_expand): Conv2dStaticSamePadding(\n          10, 240, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_project_conv): Conv2dStaticSamePadding(\n          240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_swish): MemoryEfficientSwish()\n      )\n      (6-7): 2 x MBConvBlock(\n        (_expand_conv): Conv2dStaticSamePadding(\n          80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_depthwise_conv): Conv2dStaticSamePadding(\n          480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n          (static_padding): ZeroPad2d((1, 1, 1, 1))\n        )\n        (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_se_reduce): Conv2dStaticSamePadding(\n          480, 20, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_se_expand): Conv2dStaticSamePadding(\n          20, 480, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_project_conv): Conv2dStaticSamePadding(\n          480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_swish): MemoryEfficientSwish()\n      )\n      (8): MBConvBlock(\n        (_expand_conv): Conv2dStaticSamePadding(\n          80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_depthwise_conv): Conv2dStaticSamePadding(\n          480, 480, kernel_size=(5, 5), stride=[1, 1], groups=480, bias=False\n          (static_padding): ZeroPad2d((2, 2, 2, 2))\n        )\n        (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_se_reduce): Conv2dStaticSamePadding(\n          480, 20, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_se_expand): Conv2dStaticSamePadding(\n          20, 480, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_project_conv): Conv2dStaticSamePadding(\n          480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_swish): MemoryEfficientSwish()\n      )\n      (9-10): 2 x MBConvBlock(\n        (_expand_conv): Conv2dStaticSamePadding(\n          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_depthwise_conv): Conv2dStaticSamePadding(\n          672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n          (static_padding): ZeroPad2d((2, 2, 2, 2))\n        )\n        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_se_reduce): Conv2dStaticSamePadding(\n          672, 28, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_se_expand): Conv2dStaticSamePadding(\n          28, 672, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_project_conv): Conv2dStaticSamePadding(\n          672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_swish): MemoryEfficientSwish()\n      )\n      (11): MBConvBlock(\n        (_expand_conv): Conv2dStaticSamePadding(\n          112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_depthwise_conv): Conv2dStaticSamePadding(\n          672, 672, kernel_size=(5, 5), stride=[2, 2], groups=672, bias=False\n          (static_padding): ZeroPad2d((1, 2, 1, 2))\n        )\n        (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_se_reduce): Conv2dStaticSamePadding(\n          672, 28, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_se_expand): Conv2dStaticSamePadding(\n          28, 672, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_project_conv): Conv2dStaticSamePadding(\n          672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_swish): MemoryEfficientSwish()\n      )\n      (12-14): 3 x MBConvBlock(\n        (_expand_conv): Conv2dStaticSamePadding(\n          192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_depthwise_conv): Conv2dStaticSamePadding(\n          1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n          (static_padding): ZeroPad2d((2, 2, 2, 2))\n        )\n        (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_se_reduce): Conv2dStaticSamePadding(\n          1152, 48, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_se_expand): Conv2dStaticSamePadding(\n          48, 1152, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_project_conv): Conv2dStaticSamePadding(\n          1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_swish): MemoryEfficientSwish()\n      )\n      (15): MBConvBlock(\n        (_expand_conv): Conv2dStaticSamePadding(\n          192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_depthwise_conv): Conv2dStaticSamePadding(\n          1152, 1152, kernel_size=(3, 3), stride=[1, 1], groups=1152, bias=False\n          (static_padding): ZeroPad2d((1, 1, 1, 1))\n        )\n        (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_se_reduce): Conv2dStaticSamePadding(\n          1152, 48, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_se_expand): Conv2dStaticSamePadding(\n          48, 1152, kernel_size=(1, 1), stride=(1, 1)\n          (static_padding): Identity()\n        )\n        (_project_conv): Conv2dStaticSamePadding(\n          1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (static_padding): Identity()\n        )\n        (_bn2): BatchNorm2d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n        (_swish): MemoryEfficientSwish()\n      )\n    )\n    (_conv_head): Conv2dStaticSamePadding(\n      320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False\n      (static_padding): Identity()\n    )\n    (_bn1): BatchNorm2d(1280, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n    (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n    (_dropout): Dropout(p=0.2, inplace=False)\n    (_fc): Linear(in_features=1280, out_features=10, bias=True)\n    (_swish): MemoryEfficientSwish()\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"epochs = 10\ntrain_loss_values = []  # to store train loss for each epoch\ntrain_accuracy_values = []  # to store train accuracy for each epoch","metadata":{"execution":{"iopub.status.busy":"2023-07-22T21:22:59.370983Z","iopub.execute_input":"2023-07-22T21:22:59.371497Z","iopub.status.idle":"2023-07-22T21:22:59.377496Z","shell.execute_reply.started":"2023-07-22T21:22:59.371449Z","shell.execute_reply":"2023-07-22T21:22:59.376279Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"for epoch in range(epochs):\n    model.train()\n    train_loss = 0.0\n    correct = 0\n    total = 0\n\n    for inputs, labels in train_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item()\n        _, predicted = outputs.max(1)\n        total += labels.size(0)\n        correct += predicted.eq(labels).sum().item()\n\n    print(f'Epoch {epoch + 1}/{epochs}, Loss: {train_loss / len(train_loader):.4f}, '\n          f'Train Accuracy: {100 * correct / total:.2f}%')\n\n    train_loss_values.append(train_loss / len(train_loader))\n    train_accuracy_values.append(100 * correct / total)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluation on the test set\nmodel.eval()\ntest_loss = 0.0\ntest_correct = 0\ntest_total = 0\ny_true = []\ny_pred = []\n\nwith torch.no_grad():\n    for inputs, labels in test_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n\n        test_loss += loss.item()\n        _, predicted = outputs.max(1)\n        test_total += labels.size(0)\n        test_correct += predicted.eq(labels).sum().item()\n\n        y_true.extend(labels.cpu().numpy())\n        y_pred.extend(predicted.cpu().numpy())\n\nprint(f'Test Loss: {test_loss / len(test_loader):.4f}, Test Accuracy: {100 * test_correct / test_total:.2f}%')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the confusion matrix\ndef plot_confusion_matrix(cm, classes):\n    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n    plt.colorbar()\n\n    tick_marks = torch.arange(len(classes))\n    plt.xticks(tick_marks, classes)\n    plt.yticks(tick_marks, classes)\n\n    plt.xlabel('Predicted Label')\n    plt.ylabel('True Label')\n    plt.title('Confusion Matrix')\n    plt.tight_layout()\n\n    for i in range(len(classes)):\n        for j in range(len(classes)):\n            plt.text(j, i, str(cm[i, j]), horizontalalignment='center', verticalalignment='center', color='white')\n\n# Calculate and plot the confusion matrix\nclass_names = [str(i) for i in range(10)]\ncm = confusion_matrix(y_true, y_pred)\nplt.figure(figsize=(8, 6))\nplot_confusion_matrix(cm, classes=class_names)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot train/test loss graph\nplt.figure(figsize=(8, 6))\nplt.plot(range(1, epochs + 1), train_loss_values, label='Train Loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('Train Loss')\nplt.legend()\nplt.grid()\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot train/test accuracy graph\nplt.figure(figsize=(8, 6))\nplt.plot(range(1, epochs + 1), train_accuracy_values, label='Train Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.title('Train Accuracy')\nplt.legend()\nplt.grid()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}